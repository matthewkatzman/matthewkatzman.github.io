# In Search of an Easy Witness: Exponential Time vs. Probabilistic Polynomial Time

## Russell Impagliazzo, Valentine Kabanets, Avi Wigderson

### Main Ideas

#### <img src="/notes/papers/tex/b560ff2705f21960f31f0200a056e607.svg?invert_in_darkmode&sanitize=true" align="middle" width="268.58288655pt" height="24.65753399999998pt"/>

In other words, derandomization of <img src="/notes/papers/tex/ba007d1b3734900f1caf239e9617b838.svg?invert_in_darkmode&sanitize=true" align="middle" width="32.23728584999999pt" height="22.55708729999998pt"/> is equivalent to the existence of a hard function in <img src="/notes/papers/tex/3262497f78af8a499e76e85f7bdb9422.svg?invert_in_darkmode&sanitize=true" align="middle" width="54.42894764999999pt" height="22.55708729999998pt"/>.  The idea here is as follows:

(<img src="/notes/papers/tex/777d001ea1ec5971b67bb546ed760f97.svg?invert_in_darkmode&sanitize=true" align="middle" width="16.43840384999999pt" height="14.15524440000002pt"/>) If this is not true, then the Easy Witness Lemma does not hold.  Thus this direction is basically the proof of the Easy Witness Lemma.

(<img src="/notes/papers/tex/bd9e3b94a2cd2f370d50ece113f7b316.svg?invert_in_darkmode&sanitize=true" align="middle" width="16.43840384999999pt" height="14.15524440000002pt"/>) This is a standard application of hard functions yielding derandomizations, but assuming <img src="/notes/papers/tex/525986dc5b84a8968c8c8655d1e89fb7.svg?invert_in_darkmode&sanitize=true" align="middle" width="170.1359583pt" height="22.55708729999998pt"/>, significantly derandomizing <img src="/notes/papers/tex/ba007d1b3734900f1caf239e9617b838.svg?invert_in_darkmode&sanitize=true" align="middle" width="32.23728584999999pt" height="22.55708729999998pt"/> gives a faster deterministic simulation of <img src="/notes/papers/tex/0fa7e1e4059a89859c4afd74d72979f5.svg?invert_in_darkmode&sanitize=true" align="middle" width="39.634494899999986pt" height="22.55708729999998pt"/>, contradicting the time hierarchy theorem.

#### Hardness vs Randomness

The <img src="/notes/papers/tex/bd9e3b94a2cd2f370d50ece113f7b316.svg?invert_in_darkmode&sanitize=true" align="middle" width="16.43840384999999pt" height="14.15524440000002pt"/> direction of the above result is the contrapositive of a very standard idea - if <img src="/notes/papers/tex/3262497f78af8a499e76e85f7bdb9422.svg?invert_in_darkmode&sanitize=true" align="middle" width="54.42894764999999pt" height="22.55708729999998pt"/> is hard then there is a way to derandomize <img src="/notes/papers/tex/ba007d1b3734900f1caf239e9617b838.svg?invert_in_darkmode&sanitize=true" align="middle" width="32.23728584999999pt" height="22.55708729999998pt"/> to some extent.

The other direction presents the new concept.  That is, this is the only way that <img src="/notes/papers/tex/ba007d1b3734900f1caf239e9617b838.svg?invert_in_darkmode&sanitize=true" align="middle" width="32.23728584999999pt" height="22.55708729999998pt"/> can be derandomized.  In other words, the existence of a hard function in <img src="/notes/papers/tex/3262497f78af8a499e76e85f7bdb9422.svg?invert_in_darkmode&sanitize=true" align="middle" width="54.42894764999999pt" height="22.55708729999998pt"/> is *required*, otherwise <img src="/notes/papers/tex/ba007d1b3734900f1caf239e9617b838.svg?invert_in_darkmode&sanitize=true" align="middle" width="32.23728584999999pt" height="22.55708729999998pt"/> is just as hard as <img src="/notes/papers/tex/3262497f78af8a499e76e85f7bdb9422.svg?invert_in_darkmode&sanitize=true" align="middle" width="54.42894764999999pt" height="22.55708729999998pt"/> and adding nondeterminism to <img src="/notes/papers/tex/1badc9c9493a0421ec689d7633f092e8.svg?invert_in_darkmode&sanitize=true" align="middle" width="39.29203574999999pt" height="22.55708729999998pt"/> or randomness to <img src="/notes/papers/tex/93d804881a17daf5af04dfd29bae3c5b.svg?invert_in_darkmode&sanitize=true" align="middle" width="27.716759399999994pt" height="22.55708729999998pt"/> (both) adds a huge amount of computational power.

#### The Easy Witness Lemma

The central idea of this technique is the ability to verify language membership from a heavily reduced search space.  The paper investigates the difference between the traditional concept of verifiers and verifiers for which certificates are the truth tables of functions with small circuits (in other words, verifiers with easy witnesses of membership).  The paper discusses the consequences of equality or inequality of these two notions.

A big takeaway from this paper is as follows: if <img src="/notes/papers/tex/77fc0a70b06f5a122e80d7a9dd446aa7.svg?invert_in_darkmode&sanitize=true" align="middle" width="134.69101634999998pt" height="24.65753399999998pt"/>, then for every <img src="/notes/papers/tex/192ad4ff2d53a3ec021edaa9374abad4.svg?invert_in_darkmode&sanitize=true" align="middle" width="85.70732774999999pt" height="22.55708729999998pt"/> we can associate with any (correct) verifier a polynomial <img src="/notes/papers/tex/c62c4d1f4cea69da63734be038d89dea.svg?invert_in_darkmode&sanitize=true" align="middle" width="30.92287604999999pt" height="24.65753399999998pt"/> such that for every <img src="/notes/papers/tex/60cd4b11237e4bc3ddd5d01c0853f07d.svg?invert_in_darkmode&sanitize=true" align="middle" width="40.67336789999999pt" height="22.465723500000017pt"/> at least one accepted certificate can be compressed and represented as the truth table of circuit of size at most <img src="/notes/papers/tex/c62c4d1f4cea69da63734be038d89dea.svg?invert_in_darkmode&sanitize=true" align="middle" width="30.92287604999999pt" height="24.65753399999998pt"/>.  In other words, no matter the verifier, every <img src="/notes/papers/tex/60cd4b11237e4bc3ddd5d01c0853f07d.svg?invert_in_darkmode&sanitize=true" align="middle" width="40.67336789999999pt" height="22.465723500000017pt"/> has an "easy witness" that <img src="/notes/papers/tex/332cc365a4987aacce0ead01b8bdcc0b.svg?invert_in_darkmode&sanitize=true" align="middle" width="9.39498779999999pt" height="14.15524440000002pt"/> is in <img src="/notes/papers/tex/ddcb483302ed36a59286424aa5e0be17.svg?invert_in_darkmode&sanitize=true" align="middle" width="11.18724254999999pt" height="22.465723500000017pt"/>.

\[BFNW93\] tells us that if <img src="/notes/papers/tex/0fa7e1e4059a89859c4afd74d72979f5.svg?invert_in_darkmode&sanitize=true" align="middle" width="39.634494899999986pt" height="22.55708729999998pt"/> has small circuits (which it must if <img src="/notes/papers/tex/3262497f78af8a499e76e85f7bdb9422.svg?invert_in_darkmode&sanitize=true" align="middle" width="54.42894764999999pt" height="22.55708729999998pt"/> has small circuits), then it collapses to <img src="/notes/papers/tex/ba007d1b3734900f1caf239e9617b838.svg?invert_in_darkmode&sanitize=true" align="middle" width="32.23728584999999pt" height="22.55708729999998pt"/>.  From here, the basic idea is that, in the absence of easy witnesses, one can nondeterministically generate a hard function, which gives weak derandomization results for Arthur-Merlin.  This, in turn, gives slightly more efficient algorithms for <img src="/notes/papers/tex/0fa7e1e4059a89859c4afd74d72979f5.svg?invert_in_darkmode&sanitize=true" align="middle" width="39.634494899999986pt" height="22.55708729999998pt"/> with advice, which can be turned into fixed polynomial-sized circuits for <img src="/notes/papers/tex/0fa7e1e4059a89859c4afd74d72979f5.svg?invert_in_darkmode&sanitize=true" align="middle" width="39.634494899999986pt" height="22.55708729999998pt"/>.  Quick diagonalization shows that such circuits do not exist, so the Easy Witness Lemma holds.

### Overview

#### The Main Result

**Theorem:** <img src="/notes/papers/tex/9ff8b145b8b0b269a0062e64c43eb8d2.svg?invert_in_darkmode&sanitize=true" align="middle" width="268.58288655pt" height="24.65753399999998pt"/>.

**Lemma 1:** <img src="/notes/papers/tex/7f79b4f287a32cefcea2d5bb0245b209.svg?invert_in_darkmode&sanitize=true" align="middle" width="275.9800956pt" height="24.65753399999998pt"/>.

*Proof:* First we show (<img src="/notes/papers/tex/777d001ea1ec5971b67bb546ed760f97.svg?invert_in_darkmode&sanitize=true" align="middle" width="16.43840384999999pt" height="14.15524440000002pt"/>).  Assume that 

(1) <img src="/notes/papers/tex/77fc0a70b06f5a122e80d7a9dd446aa7.svg?invert_in_darkmode&sanitize=true" align="middle" width="134.69101634999998pt" height="24.65753399999998pt"/>.

and, for the sake of contradiction, assume that

(2) <img src="/notes/papers/tex/8de03f1ff93f09bbe377652be283542a.svg?invert_in_darkmode&sanitize=true" align="middle" width="115.98105419999997pt" height="22.831056599999986pt"/>.

If <img src="/notes/papers/tex/3262497f78af8a499e76e85f7bdb9422.svg?invert_in_darkmode&sanitize=true" align="middle" width="54.42894764999999pt" height="22.55708729999998pt"/> has easy witnesses (even considering circuits with oracle <img src="/notes/papers/tex/95d4aeb7638140fd70ba48c1d0a76c2d.svg?invert_in_darkmode&sanitize=true" align="middle" width="25.890204449999988pt" height="20.09134050000002pt"/> gates), then the witness search space is reduced to the point that one can iterate over and evaluate all candidate certificates in exponential time.  This would imply <img src="/notes/papers/tex/d5b0955968ea3cad6274f10a34ac8d12.svg?invert_in_darkmode&sanitize=true" align="middle" width="115.98105419999997pt" height="22.55708729999998pt"/>.  So by (2), there is a problem <img src="/notes/papers/tex/ddcb483302ed36a59286424aa5e0be17.svg?invert_in_darkmode&sanitize=true" align="middle" width="11.18724254999999pt" height="22.465723500000017pt"/> in <img src="/notes/papers/tex/8d6516164fea0dbeb5f2d6a973eeefd9.svg?invert_in_darkmode&sanitize=true" align="middle" width="47.032081799999986pt" height="22.465723500000017pt"/> for which easy witnesses do not exist infinitely often.

Using this fact, we create the following <img src="/notes/papers/tex/d68ffd33fdb660a33b5f4f61ed55160b.svg?invert_in_darkmode&sanitize=true" align="middle" width="36.97176944999999pt" height="29.190975000000005pt"/>-time Turing Machine <img src="/notes/papers/tex/fb97d38bcc19230b0acd442e17db879c.svg?invert_in_darkmode&sanitize=true" align="middle" width="17.73973739999999pt" height="22.465723500000017pt"/> given <img src="/notes/papers/tex/3f18d8f60c110e865571bba5ba67dcc6.svg?invert_in_darkmode&sanitize=true" align="middle" width="38.17727759999999pt" height="21.18721440000001pt"/> bits of advice.  On input lengths which do not have easy witnesses, there is at least one specific input <img src="/notes/papers/tex/36e95cdc0bd5ff0a4db1e282cb0402b8.svg?invert_in_darkmode&sanitize=true" align="middle" width="39.645998699999986pt" height="22.465723500000017pt"/> for which the certificate is hard.  Provide the string <img src="/notes/papers/tex/d0a62868544bbe8b43be9c0e7beb17cf.svg?invert_in_darkmode&sanitize=true" align="middle" width="16.58683124999999pt" height="21.18721440000001pt"/> as advice in this case.  For all other input lengths, provide <img src="/notes/papers/tex/3de7c9704c3fdf394d3bbbd915894994.svg?invert_in_darkmode&sanitize=true" align="middle" width="32.98915289999999pt" height="26.76175259999998pt"/>.  One can output <img src="/notes/papers/tex/5254e6ee076b978d5eb10b36ba83cffc.svg?invert_in_darkmode&sanitize=true" align="middle" width="22.011217799999987pt" height="28.92981300000002pt"/> and accept in this case.  Otherwise, on input of length <img src="/notes/papers/tex/55a049b8f161ae7cfeb0197d75aff967.svg?invert_in_darkmode&sanitize=true" align="middle" width="9.86687624999999pt" height="14.15524440000002pt"/>, nondeterministically guess a certificate showing <img src="/notes/papers/tex/60cd4b11237e4bc3ddd5d01c0853f07d.svg?invert_in_darkmode&sanitize=true" align="middle" width="40.67336789999999pt" height="22.465723500000017pt"/> which, by assumption, does not have small circuits, and verify normally before providing the guessed certificate as output.  <img src="/notes/papers/tex/fb97d38bcc19230b0acd442e17db879c.svg?invert_in_darkmode&sanitize=true" align="middle" width="17.73973739999999pt" height="22.465723500000017pt"/> nondeterministically generates the truth table of an infinitely-often hard function for circuits with oracles for <img src="/notes/papers/tex/95d4aeb7638140fd70ba48c1d0a76c2d.svg?invert_in_darkmode&sanitize=true" align="middle" width="25.890204449999988pt" height="20.09134050000002pt"/>.

Klivans and Melkebeek \[KM99\] showed that this ability to generate a *hard* function gives the weak *derandomization* result

(3) <img src="/notes/papers/tex/4e86b8b0cd20852ec4ac817fc5b6f8c4.svg?invert_in_darkmode&sanitize=true" align="middle" width="268.5137961pt" height="28.92981300000002pt"/>.

Now, Babai, Fortnow, Nisan, and Wigderson \[BFNW93\] show that, (1) gives us <img src="/notes/papers/tex/e9338db5ed13d5096e92191a285dca77.svg?invert_in_darkmode&sanitize=true" align="middle" width="147.94430309999998pt" height="22.55708729999998pt"/>, and combining this with (3) gives us 

(4) <img src="/notes/papers/tex/213a7f85b1da5766cc913a0a8db53f80.svg?invert_in_darkmode&sanitize=true" align="middle" width="260.0010995999999pt" height="24.65753399999998pt"/>.

Now, note that for any language <img src="/notes/papers/tex/dd48c7d3098a962704a9ae9c99fb5437.svg?invert_in_darkmode&sanitize=true" align="middle" width="187.71830054999998pt" height="24.65753399999998pt"/> with advice sequence <img src="/notes/papers/tex/819c7cae4698d7e6622b092e0b0a12c5.svg?invert_in_darkmode&sanitize=true" align="middle" width="34.07550464999999pt" height="24.65753399999998pt"/>, there is a nondeterministic machine <img src="/notes/papers/tex/f9c4988898e7f532b9f826a75014ed3c.svg?invert_in_darkmode&sanitize=true" align="middle" width="14.99998994999999pt" height="22.465723500000017pt"/> running in time <img src="/notes/papers/tex/d68ffd33fdb660a33b5f4f61ed55160b.svg?invert_in_darkmode&sanitize=true" align="middle" width="36.97176944999999pt" height="29.190975000000005pt"/> that, on input <img src="/notes/papers/tex/332cc365a4987aacce0ead01b8bdcc0b.svg?invert_in_darkmode&sanitize=true" align="middle" width="9.39498779999999pt" height="14.15524440000002pt"/>, guesses <img src="/notes/papers/tex/15a9e6cb779720a41451837d42e46a8e.svg?invert_in_darkmode&sanitize=true" align="middle" width="23.322070199999988pt" height="14.15524440000002pt"/> and verifies that <img src="/notes/papers/tex/60cd4b11237e4bc3ddd5d01c0853f07d.svg?invert_in_darkmode&sanitize=true" align="middle" width="40.67336789999999pt" height="22.465723500000017pt"/>.  Generally, there is a universal Turing Machine <img src="/notes/papers/tex/6bac6ec50c01592407695ef84f457232.svg?invert_in_darkmode&sanitize=true" align="middle" width="13.01596064999999pt" height="22.465723500000017pt"/> that, on input <img src="/notes/papers/tex/507fea80923da3e770e126ce607dd7d6.svg?invert_in_darkmode&sanitize=true" align="middle" width="35.14953089999999pt" height="24.65753399999998pt"/> simulates the <img src="/notes/papers/tex/2816079e0c533ee8a8148e5215141fe3.svg?invert_in_darkmode&sanitize=true" align="middle" width="18.06055514999999pt" height="27.91243950000002pt"/> lexicographic Turing Machine <img src="/notes/papers/tex/e8a87898efc00bd6e44ae2c7edcfcd1c.svg?invert_in_darkmode&sanitize=true" align="middle" width="20.598413549999993pt" height="22.465723500000017pt"/> for at most <img src="/notes/papers/tex/f8f25e4580c418a51dc556db0d8d2b93.svg?invert_in_darkmode&sanitize=true" align="middle" width="16.34523329999999pt" height="21.839370299999988pt"/> time steps on input <img src="/notes/papers/tex/332cc365a4987aacce0ead01b8bdcc0b.svg?invert_in_darkmode&sanitize=true" align="middle" width="9.39498779999999pt" height="14.15524440000002pt"/>, accepting if <img src="/notes/papers/tex/e8a87898efc00bd6e44ae2c7edcfcd1c.svg?invert_in_darkmode&sanitize=true" align="middle" width="20.598413549999993pt" height="22.465723500000017pt"/> accepts.  Because this can be implemented with at most quadratic overhead, <img src="/notes/papers/tex/6bac6ec50c01592407695ef84f457232.svg?invert_in_darkmode&sanitize=true" align="middle" width="13.01596064999999pt" height="22.465723500000017pt"/> runs in time <img src="/notes/papers/tex/d28295e60fcb6a3ca543858aaf794ac9.svg?invert_in_darkmode&sanitize=true" align="middle" width="22.89777929999999pt" height="26.76175259999998pt"/>.  Thus, by (1) <img src="/notes/papers/tex/6bac6ec50c01592407695ef84f457232.svg?invert_in_darkmode&sanitize=true" align="middle" width="13.01596064999999pt" height="22.465723500000017pt"/> has circuits of polynomial size, so for some <img src="/notes/papers/tex/b9798a6be0b063a31e64e1c3b8d0988c.svg?invert_in_darkmode&sanitize=true" align="middle" width="41.03867954999999pt" height="22.831056599999986pt"/>, we can implement <img src="/notes/papers/tex/6bac6ec50c01592407695ef84f457232.svg?invert_in_darkmode&sanitize=true" align="middle" width="13.01596064999999pt" height="22.465723500000017pt"/> with circuits <img src="/notes/papers/tex/472992d46a71981edd1dea7c131bd026.svg?invert_in_darkmode&sanitize=true" align="middle" width="37.135200299999994pt" height="24.65753399999998pt"/> of size <img src="/notes/papers/tex/caffed0f63065b42501fe6d23e50bbf9.svg?invert_in_darkmode&sanitize=true" align="middle" width="17.132905349999987pt" height="27.91243950000002pt"/> for large enough <img src="/notes/papers/tex/55a049b8f161ae7cfeb0197d75aff967.svg?invert_in_darkmode&sanitize=true" align="middle" width="9.86687624999999pt" height="14.15524440000002pt"/>.  This tells us that the <img src="/notes/papers/tex/2816079e0c533ee8a8148e5215141fe3.svg?invert_in_darkmode&sanitize=true" align="middle" width="18.06055514999999pt" height="27.91243950000002pt"/> lexicographic machine has circuits of size <img src="/notes/papers/tex/821c27d68262b44c38cf41f0e79f2a18.svg?invert_in_darkmode&sanitize=true" align="middle" width="151.14335279999997pt" height="27.94539330000001pt"/> (<img src="/notes/papers/tex/77a3b857d53fb44e33b53e4c8b68351a.svg?invert_in_darkmode&sanitize=true" align="middle" width="5.663225699999989pt" height="21.68300969999999pt"/> is a constant expressed in binary as input to <img src="/notes/papers/tex/6bac6ec50c01592407695ef84f457232.svg?invert_in_darkmode&sanitize=true" align="middle" width="13.01596064999999pt" height="22.465723500000017pt"/>), since we can just hard-code <img src="/notes/papers/tex/77a3b857d53fb44e33b53e4c8b68351a.svg?invert_in_darkmode&sanitize=true" align="middle" width="5.663225699999989pt" height="21.68300969999999pt"/> as the first inputs to <img src="/notes/papers/tex/269df1b24837e284ec791de3ae768620.svg?invert_in_darkmode&sanitize=true" align="middle" width="19.87487204999999pt" height="22.465723500000017pt"/> and the resulting circuit agrees with <img src="/notes/papers/tex/e8a87898efc00bd6e44ae2c7edcfcd1c.svg?invert_in_darkmode&sanitize=true" align="middle" width="20.598413549999993pt" height="22.465723500000017pt"/> (to drop the asymptotic notation, we take <img src="/notes/papers/tex/10e6efdabaa434b75fda9d534d66ecac.svg?invert_in_darkmode&sanitize=true" align="middle" width="67.85935694999998pt" height="22.831056599999986pt"/> and assume large enough <img src="/notes/papers/tex/55a049b8f161ae7cfeb0197d75aff967.svg?invert_in_darkmode&sanitize=true" align="middle" width="9.86687624999999pt" height="14.15524440000002pt"/>).  Since there is some <img src="/notes/papers/tex/77a3b857d53fb44e33b53e4c8b68351a.svg?invert_in_darkmode&sanitize=true" align="middle" width="5.663225699999989pt" height="21.68300969999999pt"/> such that <img src="/notes/papers/tex/e8a87898efc00bd6e44ae2c7edcfcd1c.svg?invert_in_darkmode&sanitize=true" align="middle" width="20.598413549999993pt" height="22.465723500000017pt"/> decides <img src="/notes/papers/tex/ddcb483302ed36a59286424aa5e0be17.svg?invert_in_darkmode&sanitize=true" align="middle" width="11.18724254999999pt" height="22.465723500000017pt"/>, we have <img src="/notes/papers/tex/96220ab4de9e9a9db5118000767ca285.svg?invert_in_darkmode&sanitize=true" align="middle" width="108.26209019999999pt" height="27.94539330000001pt"/> almost everywhere, so <img src="/notes/papers/tex/afd1d9bc915366f5445b3824dde604b9.svg?invert_in_darkmode&sanitize=true" align="middle" width="255.34126034999997pt" height="27.94539330000001pt"/> almost everywhere and, by (4),

(5) <img src="/notes/papers/tex/eb81fac0175f1014da70e12ca2ad5bf6.svg?invert_in_darkmode&sanitize=true" align="middle" width="180.54488924999998pt" height="27.94539330000001pt"/> almost everywhere.

However, consider the following algorithm: on input <img src="/notes/papers/tex/332cc365a4987aacce0ead01b8bdcc0b.svg?invert_in_darkmode&sanitize=true" align="middle" width="9.39498779999999pt" height="14.15524440000002pt"/> of length <img src="/notes/papers/tex/55a049b8f161ae7cfeb0197d75aff967.svg?invert_in_darkmode&sanitize=true" align="middle" width="9.86687624999999pt" height="14.15524440000002pt"/>, find the lexicographically first circuit <img src="/notes/papers/tex/9b325b9e31e85137d1de765f43c0f8bc.svg?invert_in_darkmode&sanitize=true" align="middle" width="12.92464304999999pt" height="22.465723500000017pt"/> on <img src="/notes/papers/tex/55a049b8f161ae7cfeb0197d75aff967.svg?invert_in_darkmode&sanitize=true" align="middle" width="9.86687624999999pt" height="14.15524440000002pt"/> inputs of size <img src="/notes/papers/tex/8224eee88e79590f29fc5f7be8ab0b6a.svg?invert_in_darkmode&sanitize=true" align="middle" width="24.92916359999999pt" height="27.91243950000002pt"/> with no equivalent circuit of size <img src="/notes/papers/tex/bb32ea06aa4bd99833ad650f5b208ac6.svg?invert_in_darkmode&sanitize=true" align="middle" width="16.709954249999992pt" height="27.91243950000002pt"/> (this can be brute forced in exponential time), and return <img src="/notes/papers/tex/7418da18c225a344fedb873186962548.svg?invert_in_darkmode&sanitize=true" align="middle" width="35.10505844999999pt" height="24.65753399999998pt"/>.  The language decided by this machine is contained in <img src="/notes/papers/tex/0fa7e1e4059a89859c4afd74d72979f5.svg?invert_in_darkmode&sanitize=true" align="middle" width="39.634494899999986pt" height="22.55708729999998pt"/>, but is not infinitely often in <img src="/notes/papers/tex/5d2787d9b937e34dfd76e2ac42022f75.svg?invert_in_darkmode&sanitize=true" align="middle" width="76.9837101pt" height="27.94539330000001pt"/>.  Thus we have found a contradiction to (5), so propogating our contradiction all the way back up to (2), we have <img src="/notes/papers/tex/8a3ba03e853c696016ef3c38745c3557.svg?invert_in_darkmode&sanitize=true" align="middle" width="115.98106079999998pt" height="22.55708729999998pt"/>.

Note that the actual contradiction derived from assuming that <img src="/notes/papers/tex/3262497f78af8a499e76e85f7bdb9422.svg?invert_in_darkmode&sanitize=true" align="middle" width="54.42894764999999pt" height="22.55708729999998pt"/> did not have easy witness circuits (otherwise we never used (2)).  This implicitly also shows the Easy Witness Lemma holds.

**Corollary 1:** <img src="/notes/papers/tex/9ff8b145b8b0b269a0062e64c43eb8d2.svg?invert_in_darkmode&sanitize=true" align="middle" width="268.58288655pt" height="24.65753399999998pt"/>.

*Proof:* Assume <img src="/notes/papers/tex/77fc0a70b06f5a122e80d7a9dd446aa7.svg?invert_in_darkmode&sanitize=true" align="middle" width="134.69101634999998pt" height="24.65753399999998pt"/>.  Then, by Lemma 1, <img src="/notes/papers/tex/d5b0955968ea3cad6274f10a34ac8d12.svg?invert_in_darkmode&sanitize=true" align="middle" width="115.98105419999997pt" height="22.55708729999998pt"/> and, by \[BFNW93\], <img src="/notes/papers/tex/bb5980de7f884b8d1477c955948ce00d.svg?invert_in_darkmode&sanitize=true" align="middle" width="93.78939899999999pt" height="22.55708729999998pt"/>, so putting these together yields <img src="/notes/papers/tex/19b7f8871f061787a955b31743ba1af7.svg?invert_in_darkmode&sanitize=true" align="middle" width="108.58384514999999pt" height="22.55708729999998pt"/>.
